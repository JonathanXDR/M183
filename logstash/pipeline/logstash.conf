input {
  beats {
    port => 5044
  }
}

filter {
  # Attempt to parse logs in JSON format first
  json {
    source => "message"
    skip_on_invalid_json => true
  }

  # Parse common log formats using Grok
  grok {
    match => { 
      "message" => [
        # Custom PHP log format: [2023-03-26 12:00:01] [ERROR] Error message here
        "\[%{TIMESTAMP_ISO8601:timestamp}\] \[%{LOGLEVEL:level}\] %{GREEDYDATA:message}",
        # Apache common log format
        "%{COMBINEDAPACHELOG}",
        # Nginx access log format (as an example of another common web server log format)
        "%{NGINXACCESS}",
        # Fallback pattern if none of the above matches
        "%{GREEDYDATA:message}"
      ]
    }
    # Remove original message to clean up the document, if needed
    remove_field => "message"
  }

  # Convert the timestamp field from the string to the actual date time format for Elasticsearch
  date {
    match => [ "timestamp", "ISO8601" ]
    remove_field => "timestamp" # Remove the string timestamp field after conversion
  }

  # Optionally, use mutate filter to rename fields, remove unwanted fields, or add new fields
  mutate {
    # Example: rename a field
    # rename => { "oldFieldName" => "newFieldName" }
    
    # Example: add application field for easy filtering in Kibana
    add_field => { "application" => "my_php_app" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
    # Optional: If using X-Pack security, uncomment these lines and replace with your credentials
    # user => "elastic"
    # password => "your_password_here"
  }
}
